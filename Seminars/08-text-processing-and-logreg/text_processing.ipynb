{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `Практикум по программированию на языке Python`\n",
    "<br>\n",
    "\n",
    "## `Занятие 8: Обработка текстов в Python`\n",
    "<br><br>\n",
    "\n",
    "### `Находнов Максим (nakhodnov17@gmail.com)`\n",
    "\n",
    "#### `Москва, 2022`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "О чём можно узнать из этого ноутбука:\n",
    "\n",
    "* Методы преобразования текстов в векторное представление\n",
    "* Стандартный пайплайн предобработки текстов\n",
    "* Базовые приёмы работы с регулярными выражениями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:18.117167Z",
     "start_time": "2022-10-27T05:32:18.027919Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `Задача обработки текстов`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Цели: \n",
    "1. Преобразование данных в формат, пригодный для использования в моделях машинного обучений — **Векторизация**\n",
    "2. Использование специфики данных для улучшения качества — **Предобработка**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T01:39:32.466006Z",
     "start_time": "2022-10-27T01:39:32.463330Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `Векторизация`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T01:39:32.466006Z",
     "start_time": "2022-10-27T01:39:32.463330Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Отличия текстового домена от табличных данных и изображений:\n",
    "1. Нет регулярной структуры\n",
    "2. Нет естественной метрики/функции расстояния\n",
    "\n",
    "$\\Longrightarrow$ попробуем преобразовать тексты в формат с которым мы уже умеем работать — **вещественные вектора**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T01:46:49.556966Z",
     "start_time": "2022-10-27T01:46:49.554573Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Векторизация. Методы`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Базовые подходы:\n",
    "    * **Мешок слов (Bag Of Words)**\n",
    "    * **Tf-Idf**\n",
    "2. Матричные разложения:\n",
    "    * LSA/LDA\n",
    "    * BigARTM\n",
    "3. Нейросетевые подходы:\n",
    "    * Word2Vec (Skip-gram, CBoW, FastText, Glove, ...)\n",
    "    * BERT\n",
    "    \n",
    "Разберём базовые методы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Формальное представление множества текстов`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T02:03:16.796695Z",
     "start_time": "2022-10-27T02:03:16.792504Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$D = \\{d_1, d_2 \\ldots d_N \\} \\; \\text{— обучающая коллекция документов}$$\n",
    "\n",
    "Обычно документы представляют в виде последовательности токенов из словаря $V$:\n",
    "\n",
    "$$d_i = (w_1, w_2, \\ldots w_{n_d}), \\quad n_d \\; \\text{— длина документа $d$}$$\n",
    "\n",
    "Выбор словаря и способа разбиения зависит от задачи!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Bag Of Words`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Предположим:\n",
    "* Порядок токенов в документе не важен\n",
    "* Важено лишь сколько раз токен $w$ входит в документ $d$: $\\text{tf}(w, d)$\n",
    "\n",
    "Тогда представим документ в виде вектора длины $|V|$:\n",
    "$$v(d) = \\{\\text{tf}(w_{1}, d), ..., \\text{tf}(w_{|V|}, d) \\} \\in \\mathbb{R}^{|V|}$$\n",
    "\n",
    "Можно выбирать разные $\\text{tf}(w, d)$ в зависимости от задачи!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T02:14:18.613829Z",
     "start_time": "2022-10-27T02:14:18.611542Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Bag Of Words. Выбор функции встречаемости` $\\text{tf}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\text{tf}(w, d)$ — term frequency weight.\n",
    "\n",
    "Варианты определения:\n",
    "$$\\text{tf}(w, d) = \\mathbb{1}[w \\in d]$$\n",
    "$$\\text{tf}(w, d) = \\sum\\limits_{w^{\\prime} \\in d} \\mathbb{1}[w = w^{\\prime}] = n_{wd}$$\n",
    "$$\\text{tf}(w, d) = \\frac{\\sum\\limits_{w^{\\prime} \\in d} \\mathbb{1}[w = w^{\\prime}]}{\\sum\\limits_{w^{\\prime} \\in d} 1} = \\frac{n_{wd}}{n_{d}}$$\n",
    "$$\\text{tf}(w, d) = 1 + \\log(n_{wd})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Tf-Idf`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "В модели BoW используется только информация о распредении слов внутри отдельных документов. Попробуем учесть распределение слов во всём корпусе текстов введя величину $\\text{idf}(w)$.\n",
    "\n",
    "Существуют разные определения, но обычно используется следующая формула:\n",
    "\n",
    "$$idf(w) = \\log \\left(\\frac{|D|}{\\sum\\limits_{d \\in {D}}\\mathbb{I}[w \\in d]} \\right) + 1$$\n",
    "\n",
    "**Модель TF-IDF:**\n",
    "\n",
    "Каждый документ представляется вектором длины $|V|$:\n",
    "$$v(d) = \\{tf(w_{1}, d) \\cdot idf(w_{1}), ..., tf(w_{|V|}, d) \\cdot idf(w_{|V|})\\} \\in \\mathbb{R}^{|V|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Реализации моделей в scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:18.520792Z",
     "start_time": "2022-10-27T05:32:18.119604Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:18.532890Z",
     "start_time": "2022-10-27T05:32:18.522710Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 1, 0],\n",
       "       [1, 0, 0, 0, 1, 1],\n",
       "       [0, 1, 1, 1, 0, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = [\n",
    "    'my name is',\n",
    "    'your name are',\n",
    "    'my father is'\n",
    "]\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit_transform(s).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:18.541336Z",
     "start_time": "2022-10-27T05:32:18.535539Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.    , 0.    , 0.5774, 0.5774, 0.5774, 0.    ],\n",
       "       [0.6228, 0.    , 0.    , 0.    , 0.4736, 0.6228],\n",
       "       [0.    , 0.6809, 0.5179, 0.5179, 0.    , 0.    ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit_transform(s).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T02:55:54.418837Z",
     "start_time": "2022-10-27T02:55:54.416377Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `BoW и Tf-Idf в сравнении с более продвинутыми моделями`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "| **Model**                         | **AG news** | **DBpedia** |\n",
    "|-----------------------------------|-------------|-------------|\n",
    "| **BoW**                           | 88.8        | 96.6        |\n",
    "| **ngrams**                        | 92.0        | 98.6        |\n",
    "| **ngrams TFIDF**                  | 92.4        | **98.7**        |\n",
    "| **char-CNN**                      | 87.2        | 98.3        |\n",
    "| **char-CRNN**                     | 91.4        | 98.6        |\n",
    "| **VDCNN**                         | 91.3        | **98.7**        |\n",
    "| **fastText (ngrams=2)**           | 92.5        | 98.6        |\n",
    "| **StarSpace (ngrams=2)**          | **92.7**        | 98.6        |\n",
    "\n",
    "<center><a href=\"https://arxiv.org/abs/1709.03856\">Подробнее результаты сравнения в статье StarSpace: Embed All The Things!</a></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Преимущества и недостатки BoW и Tf-Idf`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<font color='green'> \n",
    "    Преимущества:\n",
    "<ul>1. Простая и лёгкая в реализации модель </ul>\n",
    "<ul>2. Довольно неплохой бейзлайн </ul>\n",
    "</font>\n",
    "\n",
    "\n",
    "<font color='red'> \n",
    "    Недостатки:\n",
    "<ul>1. Огромная размерность признакового пространства: $|V| \\approx 5 \\times 10^{5}$ </ul>\n",
    "<ul>2. Разреженное представление </ul>\n",
    "<ul>3. Нет учёта контекста и порядка слов в предложении (без использования n-грамм) </ul>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Недостатки BoW и Tf-Idf. Высокая размерность`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Как бороться с огромной размерностью?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Предобработка данных\n",
    "* Методы понижения размерности (PCA)\n",
    "* Использовать другие представления (word embeddings, topic modeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `Предобработка текстов. Задачи`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Основная цель обработки текстов: улучшение качества работы алгоритмов машинного обучения. \n",
    "\n",
    "* Препроцессинг — отделение текста от \"мусора\"\n",
    "   - `<p>Атрибут href (от англ. <i>hypertext reference</i>&nbsp;)<a href=\"/html/a/target\">target</a>.</p>` *— теги, непечатные символы, Unicode, язык*\n",
    "\n",
    "* Токенизация: *I'm — один токен или два?*\n",
    "\n",
    "* Определение границ предложения: *Mr. Bing — одно предложение или два?*\n",
    "\n",
    "* Нормализация (стемминг и лемматизация): *Красивый, красивая, красивое — разные токены?*\n",
    "\n",
    "* Отбор признаков (токенов): *Нужны ли признаки для слов то, либо, нибудь?*\n",
    "\n",
    "* Выделение коллокаций (n-грамм): *Метод опорных векторов — коллокация*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Препроцессинг. Удаление лишних символов`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Обычно, не хотим различать слова с заглавной и строчной буквами $\\Rightarrow$ перед работой приводим строки в нижний регистр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:18.545423Z",
     "start_time": "2022-10-27T05:32:18.543062Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "line = 'Oh my god it is very hard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:18.550867Z",
     "start_time": "2022-10-27T05:32:18.547308Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oh my god it is very hard'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Обычно, не хотим использовать не буквы и не цифры $\\Rightarrow$ удалим все лишние символы\n",
    "\n",
    "Воспользуемся библиотекой `regex` для работы с регулярными выражениями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:18.566646Z",
     "start_time": "2022-10-27T05:32:18.552504Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' p атрибут href  от англ   i hypertext reference  i  nbsp   a href   html a target  target  a    p '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import regex\n",
    "\n",
    "s = '<p>атрибут href (от англ. <i>hypertext reference</i>&nbsp;)<a href=\"/html/a/target\">target</a>.</p>'\n",
    "regex.sub('[^a-zа-яё ]', ' ', s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Препроцессинг. Удаление лишних символов`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Знаки пунктуации можно импортировать из модуля `string`. В нем хранятся различные наборы констант для работы со строками (пунктуация, алфавит и др.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:18.572491Z",
     "start_time": "2022-10-27T05:32:18.568319Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Обратите вниманине, не всегда пунктуация является шумовым признаком! Например, в задаче sentiment analysis смайлики могут существенно влиять на качество модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Введение в регулярные выражения. Поиск совпадений`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`regex.search` может работать как `str.find`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:18.578950Z",
     "start_time": "2022-10-27T05:32:18.574490Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line.find('is very')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:18.587314Z",
     "start_time": "2022-10-27T05:32:18.583325Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<regex.Match object; span=(13, 20), match='is very'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex.search('is very', line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`regex.search` может работать как `str.startwith`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:18.593020Z",
     "start_time": "2022-10-27T05:32:18.589124Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line.startswith('is very')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:18.597792Z",
     "start_time": "2022-10-27T05:32:18.594822Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "regex.search('^is very', line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:18.603567Z",
     "start_time": "2022-10-27T05:32:18.599647Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<regex.Match object; span=(0, 2), match='Oh'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex.search('^Oh', line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T03:26:52.154326Z",
     "start_time": "2022-10-27T03:26:52.151997Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Введение в регулярные выражения. Основные паттерны`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `[abcd]` — любой символ из `a, b, c, d`\n",
    "- `[a-z]`— любой символ c `a` по `z`\n",
    "- `[^xy]` — любой символ, не совпадающий с символами `x, y`\n",
    "- `()` — скобки для выделения групп символов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:18.609950Z",
     "start_time": "2022-10-27T05:32:18.605232Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<regex.Match object; span=(17, 22), match='heliO'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = 'Hello hell helio heliO'\n",
    "regex.search('[Hh]el[^l][A-Z]', line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Введение в регулярные выражения. Основные паттерны`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Метасимволы:\n",
    "- `.` — любой символ\n",
    "- `^` — начало строки\n",
    "- `$` — конец строки\n",
    "- `|` — оператор или\n",
    "- `?` — символ перед вопросом ровно ноль или один раз\n",
    "- `+` — любая ненулевая последовательность из символа перед звёздочкой\n",
    "- `*` — любая последовательность из символа перед звёздочкой (в том числе и нулевой длины)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:18.617284Z",
     "start_time": "2022-10-27T05:32:18.612081Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<regex.Match object; span=(18, 23), match='12213'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = 'Oh myyy god it is 12213'\n",
    "regex.search('[^a-zA-Z ]+', line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Введение в регулярные выражения. Основные паттерны`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Классы символов:\n",
    "- `\\s` — любой пробельный символ\n",
    "- `\\S` — любой НЕ пробельный символ\n",
    "- `\\p{Punct}` и другие `\\p{...}` — Java расширение для выделения особых классов символов. Очень полезно для работы с Unicode. [Подробнее смотри здесь](https://www.regular-expressions.info/unicode.html#prop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:18.625088Z",
     "start_time": "2022-10-27T05:32:18.619689Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<regex.Match object; span=(0, 15), match='Oh myyy        '>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = 'Oh myyy        god it is very hard'\n",
    "regex.search('Oh my*\\s*', line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Введение в регулярные выражения. Основные функции`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T03:46:22.664816Z",
     "start_time": "2022-10-27T03:46:22.661129Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`regex.compile(pattern)` — строковое представление выражения преобразуется в программное:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:18.630859Z",
     "start_time": "2022-10-27T05:32:18.627219Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pattern = regex.compile(u'[^a-zа-яё ]+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`regex.sub(pattern, repl, string, count=0)` — заменить `count` символов в `string`, удовлетворяющих `pattern`, на `repl`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:18.637241Z",
     "start_time": "2022-10-27T05:32:18.633027Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1995!!!!r was...'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex.sub('[^0-9]', '!', '1995 year was...', count=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Введение в регулярные выражения. Основные функции`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T03:51:58.333031Z",
     "start_time": "2022-10-27T03:51:58.329492Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`regex.split(pattern, string, maxsplit=0)` — split по символам, удовлетворяющим `pattern`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:18.644014Z",
     "start_time": "2022-10-27T05:32:18.639113Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i look for', ' for many years', ' in']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex.split('[^a-z ]', \"i look for. for many years. in\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`regex.findall(pattern, string)` — выделение всех непереесекающихся подстрок в строке `string`, удовлетворяющих шаблону `pattern`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:18.651977Z",
     "start_time": "2022-10-27T05:32:18.646207Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('001', '5')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex.findall('experiment_([0-9]*)_k=\\(([0-9])\\)', 'sometext_experiment_001_k=(5)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T04:00:58.070526Z",
     "start_time": "2022-10-27T04:00:58.067147Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Регулярные выражения. Полезные ссылки`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T04:04:00.343347Z",
     "start_time": "2022-10-27T04:04:00.338337Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- [Документация библиотеки `re`](https://docs.python.org/3/library/re.html)\n",
    "- [Сервис онлайн проверки регулярных выражений](https://regex101.com/)\n",
    "- [Упражнения на регулярные выражения](https://regexone.com/)\n",
    "- [\"Регулярный\" кроссворд](https://mariolurig.com/crossword/)\n",
    "- [Ещё хорошая справка](https://www.regular-expressions.info/quickstart.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `Токенизация`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Токенизация — разделение текста на токены, элементарные единицы текста\n",
    "\n",
    "В большинстве случае токен это слово!\n",
    "\n",
    "Если пользоваться методом .split(), токен — последовательность букв, разделённая пробельным символам\n",
    "\n",
    "Можно использовать регулярные выражения и модуль `regex`\n",
    "\n",
    "Можно использовать специальные токенизаторы, например из\n",
    "`nltk`:\n",
    "- `RegexpTokenizer`\n",
    "- `BlanklineTokenizer`\n",
    "- И ещё около десятка штук"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Библиотека nltk. Токенизаторы`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:19.192212Z",
     "start_time": "2022-10-27T05:32:18.654052Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/nakhodnov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nakhodnov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt');\n",
    "nltk.download('stopwords');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Встроенные токенизаторы могут быть значительно \"умнее\" обычного `.split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:19.199951Z",
     "start_time": "2022-10-27T05:32:19.194236Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Но', 'не', 'каждый', 'хочет', 'что-то', 'исправлять', ':', '(']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = 'Но не каждый хочет что-то исправлять:('\n",
    "word_tokenize(example, language='russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:19.205270Z",
     "start_time": "2022-10-27T05:32:19.201538Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Но', 'не', 'каждый', 'хочет', 'что-то', 'исправлять:(']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Библиотека nltk. Токенизаторы`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Так же в этой библиотеке есть более спецефичные токенизаторы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:19.211274Z",
     "start_time": "2022-10-27T05:32:19.207226Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['do', \"n't\", 'stop', 'me']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.tokenize.TreebankWordTokenizer().tokenize(\"don't stop me\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:19.217081Z",
     "start_time": "2022-10-27T05:32:19.213152Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(a (b c))', 'd', 'e', '(f)']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.tokenize.SExprTokenizer().tokenize(\"(a (b c)) d e (f)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `Разбиение на предложения`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T04:12:43.179833Z",
     "start_time": "2022-10-27T04:12:43.176383Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Простой вариант:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:19.223013Z",
     "start_time": "2022-10-27T05:32:19.218948Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hey', ' Is Mr', ' Bing waiting for you', '']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'Hey! Is Mr. Bing waiting for you?'\n",
    "regex.split('[!.?]+', sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Можно учитывать разные исключения при разделении:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:19.230469Z",
     "start_time": "2022-10-27T05:32:19.224866Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hey!', 'Is Mr. Bing waiting for you?']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentenceEnders = regex.compile(r\"\"\"\n",
    "(?: # Group for two positive lookbehinds.\n",
    "(?<=[.!?]) # Either an end of sentence punct,\n",
    "| (?<=[.!?]['\"]) # or end of sentence punct and quote.\n",
    ") # End group of two positive lookbehinds.\n",
    "(?<! Mr\\. ) # Don't end sentence on \"Mr.\"\n",
    "(?<! Mrs\\. ) # Don't end sentence on \"Mrs.\"\n",
    "\\s+ # Split on whitespace between sentences.\n",
    "\"\"\", regex.IGNORECASE | regex.VERBOSE)\n",
    "sentenceEnders.split(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:05:50.837331Z",
     "start_time": "2022-10-27T05:05:50.835100Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## `Разбиение на предложения`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Или использовать готовую реализацию из `nltk`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:19.248145Z",
     "start_time": "2022-10-27T05:32:19.237477Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hey!', 'Is Mr. Bing waiting for you?']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.tokenize.sent_tokenize(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `Отбор слов`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Какие слова могут быть плохие?\n",
    "* Слишком частые\n",
    "    - *русский язык: и, но, я, ты, ...*\n",
    "    - *английский язык: a, the, I, one, ...*\n",
    "    - *специфичные для коллекции: «сообщать» в новостях*\n",
    "* Слишком редкие (встречаются в $\\leq 5$ документах)\n",
    "* Стоп-слова (предлоги, междометия, частицы, цифры)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:19.256115Z",
     "start_time": "2022-10-27T05:32:19.250141Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"doesn't\", 'having', \"weren't\", \"mightn't\", 'own', 'o']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopWords = set(stopwords.words('english'))\n",
    "list(stopWords)[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Замена сокращений с помощью regex.sub`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:19.264255Z",
     "start_time": "2022-10-27T05:32:19.258236Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'where <stop> your spoon daddy'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def delete_to_be(text_string):\n",
    "    return regex.sub(\"('s|'re|n't)\\s\", u' <stop> ', text_string.lower())\n",
    "    \n",
    "delete_to_be(\"Where's your spoon daddy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:19.271424Z",
     "start_time": "2022-10-27T05:32:19.266739Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'why do <stop> you like me'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delete_to_be(\"Why don't you like me\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Замена специфичных сущностей на теги`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:19.277211Z",
     "start_time": "2022-10-27T05:32:19.273724Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sentence = \"\"\"\n",
    "Контактную информацию вы можете уточнить, перейдя по ссылке\n",
    "https://minust.ru/structure/00000000000\n",
    "(выбрать раздел &quot;Территориальные органы и подведомственные\n",
    "организации&quot;, выбрать регион и открыть вкладку\n",
    "&quot;Информация и контакты&quot;)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:19.286323Z",
     "start_time": "2022-10-27T05:32:19.279488Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Контактную информацию вы можете уточнить , перейдя по ссылке <URL> ( выбрать раздел \" ; Территориальные органы и подведомственные организации \" ; , выбрать регион и открыть вкладку \" ; Информация и контакты \" ; )'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_string = regex.sub('&quot', ' \" ', sentence)\n",
    "result_string = regex.sub('(http|www)\\S+', ' <URL> ', result_string)\n",
    "result_string = regex.sub('([^\\w\\s<>])', ' \\\\1 ', result_string)\n",
    "\n",
    "\" \".join(result_string.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `Нормализация слов`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Стемминг`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T04:22:59.399248Z",
     "start_time": "2022-10-27T04:22:59.395403Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Стемминг — отбрасывание окончаний слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:19.292755Z",
     "start_time": "2022-10-27T05:32:19.288153Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'georg admit the talk happen'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "sentence = 'George admitted the talks happened'.split()\n",
    "\" \".join([stemmer.stem(word) for word in sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:19.299153Z",
     "start_time": "2022-10-27T05:32:19.294509Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'write wrote written'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'write wrote written'.split()\n",
    "\" \".join([stemmer.stem(word) for word in sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Стемминг для русского языка`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Для русского языка стемминг не очень подходит:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:19.305681Z",
     "start_time": "2022-10-27T05:32:19.300987Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'опрошен счита налог необходим'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(language='russian')\n",
    "sentence = 'опрошенных считают налоги необходимыми'.split()\n",
    "\" \".join([stemmer.stem(word) for word in sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:19.312085Z",
     "start_time": "2022-10-27T05:32:19.307619Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'пол пол полет полк полк'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'поле пол полёт полка полк'.split()\n",
    "\" \".join([stemmer.stem(word) for word in sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:19.318735Z",
     "start_time": "2022-10-27T05:32:19.314227Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'крут круч крут крут'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'крутой круче крутейший крутить'.split()\n",
    "\" \".join([stemmer.stem(word) for word in sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Вспомогательная задача — определение части речи`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:19.324541Z",
     "start_time": "2022-10-27T05:32:19.320727Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    my_switch = {\n",
    "        'J': wordnet.ADJ, 'V': wordnet.VERB,\n",
    "        'N': wordnet.NOUN, 'R': wordnet.ADV\n",
    "    }\n",
    "    for key, item in my_switch.items():\n",
    "        if treebank_tag.startswith(key):\n",
    "            return item\n",
    "    return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:19.431445Z",
     "start_time": "2022-10-27T05:32:19.326518Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('George', 'NNP'),\n",
       " ('admitted', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('talks', 'NNS'),\n",
       " ('happened', 'VBD')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'George admitted the talks happened'.split()\n",
    "pos_taged = nltk.pos_tag(sentence)\n",
    "pos_taged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:20.684027Z",
     "start_time": "2022-10-27T05:32:19.433639Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n', 'v', 'n', 'n', 'v']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[get_wordnet_pos(tag) for word, tag in pos_taged]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Лемматизация`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Лемматизация** – это сведение разных форм одного слова к начальной форме – **лемме**. Почему это хорошо?\n",
    "* Во-первых, естественно рассматривать как отдельный признак каждое *слово*, а не каждую его отдельную форму.\n",
    "* Во-вторых, некоторые стоп-слова стоят только в начальной форме, и без лематизации выкидываем мы только её."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T04:30:15.529731Z",
     "start_time": "2022-10-27T04:30:15.525843Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Для английского можно использовать лемматизатор `WordNet`. Однако, он требует для работы метки частей речи!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Лемматизация`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:20.689142Z",
     "start_time": "2022-10-27T05:32:20.685982Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import WordNetLemmatizer\n",
    "\n",
    "def simple_lemmatizer(sentence):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokenized_sent = sentence.split()\n",
    "    pos_taged = [\n",
    "        (word, get_wordnet_pos(tag))\n",
    "        for word, tag in nltk.pos_tag(tokenized_sent)\n",
    "    ]\n",
    "    return \" \".join([\n",
    "        lemmatizer.lemmatize(word, tag)\n",
    "        for word, tag in pos_taged\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:20.695144Z",
     "start_time": "2022-10-27T05:32:20.690665Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'George admit the talk happen'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_lemmatizer('George admitted the talks happened')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:20.701716Z",
     "start_time": "2022-10-27T05:32:20.696958Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'write write write'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_lemmatizer('write wrote written')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Лемматизация для русского языка`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Для русского есть два хороших лемматизатора: mystem и pymorphy.\n",
    "\n",
    "[Mystem](https://tech.yandex.ru/mystem/) Как с ним работать:\n",
    "* можно скачать mystem и запускать [из терминала с разными параметрами](https://tech.yandex.ru/mystem/doc/)\n",
    "* [pymystem3](https://pythonhosted.org/pymystem3/pymystem3.html) - обертка для питона, работает медленнее, но это удобно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:09:25.694526Z",
     "start_time": "2022-10-27T05:09:25.692016Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Лемматизация для русского языка`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:20.801787Z",
     "start_time": "2022-10-27T05:32:20.703451Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "def simple_lemmatizer(sentence):\n",
    "    lemmatizer = pymorphy2.MorphAnalyzer()\n",
    "    tokenized_sent = sentence.split()\n",
    "    return \" \".join([\n",
    "        lemmatizer.parse(word)[0].normal_form\n",
    "        for word in tokenized_sent\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:20.899833Z",
     "start_time": "2022-10-27T05:32:20.804383Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'опросить считать налог необходимый'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_lemmatizer('опрошенных считают налоги необходимы')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:20.995842Z",
     "start_time": "2022-10-27T05:32:20.901853Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'поле пол полёт полка полк'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_lemmatizer('поле пол полёт полка полк')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T04:34:11.391009Z",
     "start_time": "2022-10-27T04:34:11.386985Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`Pymorphy2` не требует метку части речи, но для улучшения разбора, её можно использовать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Заключение о нормализации и отборе слов`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Отбор слов\n",
    "* Нужен почти всегда для всех языков\n",
    "* Можно сократить словарь до $100000$ токенов почти без потери качества\n",
    "\n",
    "Стемминг\n",
    "* Плохо работает для русского языка\n",
    "* Нормально работает для английского, но модели хорошо работают и без него\n",
    "\n",
    "Лемматизация\n",
    "* Лучше стемминга для русского языка\n",
    "* Сильно повышает качество моделей для русского языка\n",
    "* Хорошо работает и для английского, но модели хорошо работают и без неё\n",
    "* Гораздо медленнее чем стемминг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `Последовательности слов`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Попробуем решить проблему BoW/Tf-Idf, учитывая не только сами токены, но и их контекст.\n",
    "\n",
    "Рассмотрим разные сущности на примере предложения:\n",
    "\n",
    "**<center>Метод опорных векторов — метод машинного обучения.**\n",
    "\n",
    "* Коллокации — устойчивые словосочетания\n",
    "    - `метод опорных векторов, метод машииного обучения, опорных векторов, машинного обучения`\n",
    "* $n$-граммы — последовательности из n слов\n",
    "    - $2$-граммы: `метод опорных, опорных векторов, векторов метод, метод машинного, машинного обучения`\n",
    "* $s$-скип-$n$-граммы — последовательности из $n$ слов с $s$ пропусками\n",
    "    - $1$-скип-$2$-граммы: `метод векторов, опорных метод, векторов машинного, метод обучения`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Выделение n-грамм`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:00:28.433703Z",
     "start_time": "2022-10-27T05:00:28.429989Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "В scikit-learn есть встроенное выделение n-грамм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:21.003178Z",
     "start_time": "2022-10-27T05:32:20.997742Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 1, 0],\n",
       "       [1, 0, 0, 0, 1, 1],\n",
       "       [0, 1, 1, 1, 0, 0]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = ['my name is', 'your name are', 'my father is']\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1))\n",
    "vectorizer.fit_transform(s).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:21.009651Z",
     "start_time": "2022-10-27T05:32:21.004700Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1],\n",
       "       [0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "vectorizer.fit_transform(s).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T05:32:21.014440Z",
     "start_time": "2022-10-27T05:32:21.011525Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'my': 4, 'name': 7, 'is': 3, 'my name': 6, 'name is': 9, 'your': 10, 'are': 0, 'your name': 11, 'name are': 8, 'father': 1, 'my father': 5, 'father is': 2}\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Как можно получать коллокации`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Извлечение биграмм на основе частот и морфологических шаблонов\n",
    "* Поиск разрывных коллокаций\n",
    "* Извлечение биграмм на основе мер ассоциации и статистических критериев (TopMine)\n",
    "* Алгоритм `TextRank` для извлечения словосочетаний\n",
    "* Rapid Automatic Keyword Extraction\n",
    "* Выделение ключевых слов по Tf-Idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Выделение частотных коллокаций`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Статистические алгоритмы выделения коллокаций основаны на том, что коллокацией являются слова, часто встречающиеся рядом друг с другом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**ENSURE** $\\{(w, u)\\}~\\text{— множество коллокаций из}~2~\\text{слов}$\n",
    "\n",
    "$n_{wu}~:=~0,~\\forall~w,~u~\\in~V'$\n",
    "\n",
    "**FOR** ($i=1,~\\dots,~N$) **DO**\n",
    "\n",
    "$~~~~$**FOR** ($j=1,~\\dots,~n_d - 1$) **DO**\n",
    "\n",
    "$~~~~~~~~n_{wu}~=~n_{wu}~+~\\mathbb{1}[w_{j + 1}^d = w,~w_{j}^d = u]~\\forall w, u \\in V'$\n",
    "\n",
    "$s~=~\\{(w,u)~|~n_{wu}>t\\}$\n",
    "\n",
    "**RETURN** $s$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Без выделения стоп-слов подобные алгоритмы будут работать очень плохо!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `Стандартные этапы обработки текстов`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Можно выделить следующие этапы:\n",
    "1. Удаление специфичных символов/последовательностей\n",
    "2. Приведение к нижнему регистру\n",
    "3. Токенизация\n",
    "4. Лемматизация\n",
    "5. Выделение коллокаций\n",
    "6. Удаление стоп-слов / Сокращение словаря\n",
    "\n",
    "Почти всегда правильная обработка приводит к улучшению качества и уменьшению времени работы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `Спасибо за внимание!`"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Слайд-шоу",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
