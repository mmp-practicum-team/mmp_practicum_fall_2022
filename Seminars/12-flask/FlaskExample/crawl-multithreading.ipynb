{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import codecs\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "\n",
    "import regex\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "\n",
    "# In case of Windows System go to https://www.lfd.uci.edu/~gohlke/pythonlibs/#pycurl and download binary\n",
    "# ! pip install --user ./pycurl‑7.43.0.3‑cp37‑cp37m‑win_amd64.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get All Movie Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.kinopoisk.ru/lists/navigator/{0}/?page={1}&tab=all'\n",
    "MOVIE_URLS = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your cookie from https://www.kinopoisk.ru/lists/navigator/2021/\n",
    "cookies = '''\n",
    "# SET YOUR COOKIE HERE\n",
    "'''.replace('\\n', '').split('; ')\n",
    "\n",
    "cookies = {\n",
    "    key: '='.join(values) for key, *values in [cookie.split('=') for cookie in cookies]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in [2021, 2020, 2019, 2018, 2017, 2016, 2015]:\n",
    "    for page_idx in range(1, 30):\n",
    "        result = requests.request('GET', base_url.format(year, page_idx), cookies=cookies)\n",
    "        soup = BeautifulSoup(result.content.decode(), 'lxml')\n",
    "        \n",
    "        films_div = soup.find_all('div', {'class': regex.compile('desktop-seo-selection-film-item selection-list__film')})\n",
    "        for film_div in films_div:\n",
    "            film_href = film_div.findAll('a', {'class': regex.compile('selection-film-item-meta__link')})[0].attrs['href']\n",
    "            MOVIE_URLS.add(film_href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total movie urls: 7180\n",
      "Examples: \n",
      "/film/957899/\n",
      "/film/1297198/\n",
      "/film/839818/\n",
      "/film/843787/\n",
      "/film/679565/\n"
     ]
    }
   ],
   "source": [
    "MOVIE_URLS = list(MOVIE_URLS)\n",
    "print('Total movie urls: %d' % len(MOVIE_URLS))\n",
    "print('Examples: \\n%s' % '\\n'.join(MOVIE_URLS[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_reviews_url = 'https://www.kinopoisk.ru{0}reviews/ord/date/status/all/perpage/200/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_with_newlines(elem):\n",
    "    text = ''\n",
    "    for e in elem.recursiveChildGenerator():\n",
    "        if isinstance(e, str):\n",
    "            text += e.strip()\n",
    "        elif e.name == 'br':\n",
    "            text += '\\n'\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_movie(movie_href):\n",
    "    results = []\n",
    "    try:\n",
    "        for idx in range(1):\n",
    "            result = requests.request('GET', base_reviews_url.format(movie_href), cookies=cookies)\n",
    "            soup = BeautifulSoup(result.content.decode(), 'lxml')\n",
    "\n",
    "            reviews = soup.find_all('div', {'class': 'reviewItem userReview'})\n",
    "            if not reviews:\n",
    "                base = {'content': soup.extract(), 'name': movie_href}\n",
    "                results.append(base)\n",
    "                break\n",
    "            for rewiev in reviews:\n",
    "                rewiev_content = rewiev.find('div', {'class': regex.compile('response .*')})\n",
    "                sentiment = rewiev_content.attrs['class'][1]\n",
    "                text = rewiev_content.find('span', {'class': '_reachbanner_'})\n",
    "                text = text_with_newlines(text).replace('\\n', '')\n",
    "                \n",
    "                base = {'content': soup.extract(), 'name': movie_href}\n",
    "                base['sentiment'] = sentiment\n",
    "                base['text'] = text\n",
    "                results.append(base)\n",
    "            else:\n",
    "                break\n",
    "    except Exception as e:\n",
    "        logging.error('%s %s' % (movie_href, str(e)))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [02:56,  1.70it/s]                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 11986 reviews\n",
      "Class balance: \n",
      "{0} {\n",
      "    \"good\": 7384,\n",
      "    \"bad\": 2311,\n",
      "    \"neutral\": 2291\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pool_size = 24\n",
    "\n",
    "all_reviews = []\n",
    "\n",
    "total_reviews = 0\n",
    "class_counters = defaultdict(int)\n",
    "with open('./artifacts/data.csv', 'w', encoding='utf-8', errors='ignore') as file:\n",
    "    for urls_chunk in tqdm(chunks(MOVIE_URLS, pool_size), total=len(MOVIE_URLS) // pool_size):\n",
    "        pool = ThreadPool(pool_size)\n",
    "        movies_reviews = pool.map(process_movie, urls_chunk)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        for movie_reviews in movies_reviews:\n",
    "            all_reviews += movie_reviews\n",
    "            for review in movie_reviews:\n",
    "                if 'text' in review:\n",
    "                    file.write('{0}\\t{1}\\t{2}\\n'.format(review['name'], review['sentiment'], review['text']))\n",
    "                    total_reviews += 1\n",
    "                    class_counters[review['sentiment']] += 1\n",
    "        file.flush()\n",
    "                \n",
    "print('Total {0:d} reviews'.format(total_reviews))\n",
    "print('Class balance: \\n{0}',format(json.dumps(class_counters, indent=4)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "c43a086bac68110ae6dfbc1d850e1f294ea3e6e404ed8e3b35a44ce4deb7d26f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
