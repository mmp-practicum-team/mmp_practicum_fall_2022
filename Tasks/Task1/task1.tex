\documentclass[10pt,fleqn]{article}

\usepackage[russian]{babel}
\usepackage[utf8]{inputenc}
\usepackage{color}
\usepackage{upquote,textcomp}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphics}
\usepackage{epsfig}
\usepackage{bm}
\usepackage[colorlinks,urlcolor=blue]{hyperref}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{verbatim}
\usepackage{mdframed}
\usepackage{dirtree}
\usepackage{indentfirst}
\usepackage{url}

\definecolor{codegray}{gray}{0.9}
\newcommand{\code}[1]{%
  \begingroup\setlength{\fboxsep}{1pt}%
  \colorbox{codegray}{\texttt{\hspace*{2pt}\vphantom{Ay}#1\hspace*{2pt}}}%
  \endgroup
}

\newcommand\upquote[1]{\textquotesingle#1\textquotesingle}

\textheight=26cm % высота текста
\textwidth=18cm % ширина текста
\oddsidemargin=-1cm % отступ от левого края
\topmargin=-2.5cm % отступ от верхнего края
\sloppy

\newcounter{example}

\definecolor{mdinlinecodeboxframecolor}{HTML}{DDDDDD}
\definecolor{mdinlinecodeboxbackgroundcolor}{HTML}{F8F8F8}
\newcommand{\mdinlinecode}[1]{%
    \begin{tikzpicture}[baseline=0ex]%
        \node[anchor=base,%
            text height=0.9em,%
            text depth=0.9ex,%
            inner ysep=0pt,%
            draw=mdinlinecodeboxframecolor,%
            fill=mdinlinecodeboxbackgroundcolor,%
            rounded corners=1.5pt] at (0,0) {\small\texttt{#1}};%
    \end{tikzpicture}%
}

%-- Обозначение вектора жирным символом
\def\vec#1{\mathchoice{\mbox{\boldmath$\displaystyle#1$}}
{\mbox{\boldmath$\textstyle#1$}} {\mbox{\boldmath$\scriptstyle#1$}} {\mbox{\boldmath$\scriptscriptstyle#1$}}}

\DeclareMathOperator{\B}{Bin}
\DeclareMathOperator{\Ps}{Poiss}
\DeclareMathOperator{\R}{Unif}
\DeclareMathOperator{\real}{\mathbb{R}}


\pagestyle{empty}

\begin{document}

\begin{center}
    \begin{tabular}{|p{17.5cm}|}
        \hline
        \textbf{ВМК}\\
        \begin{center} \Large Задание 1. Метрические алгоритмы классификации\end{center}\\
        \textbf{Практикум 317 группы, 2022}\\
        \hline
    \end{tabular}
\end{center}

\

\begin{tabbing}
    Начало выполнения задания: 30 сентября 2022 года, 18:00.\\
    Мягкий дедлайн: \textcolor{blue}{\bf 15 октября 2022 года, 01:00.}\\
    Жёсткий дедлайн: \textcolor{red}{\bf 22 октября 2022 года, 01:00.}
\end{tabbing}

%\tableofcontents

\section*{Формулировка задания}

Данное задание направлено на ознакомление с метрическими алгоритмами классификации, а также методами работы с изображениями.
В задании необходимо:
\begin{enumerate}
 \item Написать на языке \mdinlinecode{Python} собственные реализации метода ближайших соседей и кросс-валидации. Реализации должны соответствовать требованиям, описанным ниже. Стиль кода должен соответствовать требованиям, указанным на \href{https://github.com/mmp-practicum-team/mmp_practicum_fall_2022#требования-к-программному-коду}{сайте курса}. Невыполнение будет штрафоваться.

 \item Провести \hyperref[sec:exps]{описанные ниже эксперименты} с датасетом изображений цифр \texttt{MNIST}.
 
 \item Написать отчёт о проделанной работе (формат PDF). Отчёт должен быть подготовлен в системе \LaTeX. Отчет должен удовлетворять требованиям, указанным на  \href{https://github.com/mmp-practicum-team/mmp_practicum_fall_2022#требования-к-отчёту-по-практическим-заданиям}{сайте курса}. Невыполнение будет штрафоваться.
 
 \item В систему проверки anytask сдаётся .zip архив с модулями с написанным кодом, jupyter-notebook с кодом экспериментов (может быть не структурирован, проверяется при наличии вопросов к результатам экспериментов) и отчёт. Архив необходимо назвать \texttt{task1\_{фамилия}\_{имя}.zip}.
\end{enumerate}

\section*{Список экспериментов\label{sec:exps}}
Эксперименты этого задания необходимо проводить на датасете \texttt{MNIST}.
Загрузить датасет можно при помощи функции \mdinlinecode{sklearn.datasets.fetch\_openml("mnist\_784")} или скачать вручную с сайта \url{http://yann.lecun.com/exdb/mnist/}. В первом случае для удобства стоит перевести датасет в numpy-массивы,  с помощью метода \mdinlinecode{to\_numpy()}.
Датасет необходимо разбить на обучающую выборку (первые 60 тыс. объектов) и тестовую выборку (10 тыс. последних объектов).  

\begin{enumerate}

\item
  Исследуйте, какой алгоритм поиска ближайших соседей будет быстрее работать в различных ситуациях и почему.

Измерьте для каждого алгоритма поиска (\upquote{kd\_tree}, \upquote{ball\_tree}, \upquote{brute} и \upquote{my\_own}) время нахождения 5 ближайших соседей для каждого объекта тестовой выборки по евклидовой метрике. Выберите подмножество признаков, по которому будет считаться расстояние, размера 10, 20, 100 (подмножество признаков выбирается один раз для всех объектов, случайно).
  Проверьте все алгоритмы поиска ближайших соседей, указанные в спецификации к заданию.  
  
  \textbf{Замечание.}
  Для оценки времени долго работающих функций можно пользоваться либо функциями из модуля \mdinlinecode{time}, либо magic-командой \mdinlinecode{\%time}, которая запускает код лишь один раз. 

  
\item
  Оцените по кросс-валидации с 3 фолдами точность (долю правильно предсказанных ответов) и время работы k ближайших соседей в зависимости от следующих факторов:
  \begin{enumerate}
    \item k от 1 до 10 (только влияние на точность).
    \item Используется евклидова или косинусная метрика.
  \end{enumerate}
  
  Дайте ответ на следующие вопросы:
  \begin{enumerate}
      \item Какая метрика лучше себя показала в экспериментах? Можете ли вы объяснить, почему?
      \item Есть ли на графике зависимости точности от количество соседей выбросы, резкие падения/повышения качества для одного значения k по сравнению с соседними? Если да, предположите причину появления этих выбросов.
  \end{enumerate}

  
\item
Сравните взвешенный метод k ближайших соседей, где голос объекта равен $1 / (distance + \varepsilon)$, где $\varepsilon$ "--- $10^{-5}$,
с методом без весов при тех же фолдах и параметрах. Невыполнение будет штрафоваться.


\item
  Примените лучший алгоритм к исходной обучающей и тестовой выборке. Подсчитайте точность.
  Сравните с точностью по кросс-валидации. Сравните с указанной в интернете точностью лучших алгоритмов на данной выборке.
Выполните анализ ошибок. Для этого необходимо построить и проанализировать матрицу ошибок (confusion matrix). Также визуализируйте несколько объектов из тестовой выборки, на которых были допущены ошибки. Проанализируйте и указажите их общие черты.

\textbf{Замечание.}
Для построения матрицы можно воспользоваться функцией \mdinlinecode{sklearn.metrics.confusion\_matrix}.
Для визуализации можно воспользоваться \mdinlinecode{pyplot.subplot}, и \mdinlinecode{pyplot.imshow} с параметром \mdinlinecode{cmap="Greys"}. Также можно убрать оси координат при помощи команды \mdinlinecode{pyplot.axis("off")}.


\item
Выполните аугментацию обучающей выборки. Для этого нужно размножить ее с помощью поворотов, смещений, морфологических операций и применений гауссовского фильтра. Разрешается использовать библиотеки для работы с изображениями.
Подберите по кросс-валидации с 3 фолдами параметры преобразований. Рассмотрите следующие параметры для преобразований и их комбинации:

\begin{enumerate}
\item Величина поворота: 5, 10, 15 (в каждую из двух сторон)

\item Величина смещения: 1, 2, 3 пикселя (по каждой из двух размерностей)

\item Дисперсия фильтра Гаусса: 0.5, 1, 1.5
\item Морфологические операции: эрозия, дилатация, открытие, закрытие с ядром 2 (\url{https://docs.opencv.org/3.4/d9/d61/tutorial_py_morphological_ops.html})
\end{enumerate}

Проанализируйте, как изменилась матрица ошибок, какие ошибки алгоритма помогает исправить каждое преобразование. 

\textbf{Замечание 1.} Не обязательно хранить все обучающие выборки в процессе эксперимента.
Достаточно вычислить ближайших соседей для каждой из выборок, а затем выбрать из них ближайших соседей.

\textbf{Замечание 2.} Размер ядра фильтра Гаусса подобрать визуально: преобразование не должно сильно портить объекты

\textbf{Замечание по дизайну эксперимента.} В этой части вам предлагается самим выбрать дизайн эксперимента. Перебор всевоможных комбинаций преобразований может быть затруднительным, в то время как жадный выбор преобразований уже даст улучшение в качестве.

\item 
Реализуйте описанный выше алгоритм, основанный на преобразовании объектов тестовой выборки.
Проверьте то же самое множество параметров, что и в предыдущем пункте.
Проанализируйте как изменилась матрица ошибок, какие ошибки алгоритма помогает исправить каждое преобразование. 
Качественно сравните два подхода (5 и 6 пункты) между собой.

\textbf{Замечание.} В рамках данного эксперимента подразумевается обучение модели на оригинальном датасете, преобразования объектов тестовой выборки, применение модели к преобразованным копиям изображения из тестовой выборки и получение результата путем голосования среди преобразованных объектов.


\end{enumerate}



\section*{Требования к реализации}

Прототипы функций должны строго соответствовать прототипам, описанным в спецификации и проходить все выданные тесты. 
Задание, не проходящее все выданные тесты, приравнивается к невыполненному.  
При написании необходимо пользоваться стандартными средствами языка \mdinlinecode{Python}, библиотеками \mdinlinecode{numpy} и \mdinlinecode{matplotlib}.
Библиотеками \mdinlinecode{scipy} и \mdinlinecode{scikit-learn} пользоваться запрещается, если это не обговорено отдельно в пункте задания.
Для экспериментов в двух последних пунктах разрешается пользоваться любыми открытыми библиотеками, реализующими алгоритмы обработки изображений.

\textbf{Замечание 1.} Далее под выборкой объектов будем понимать \texttt{np.ndarray} размера $N \times D$ или разреженную матрицу \mdinlinecode{scipy.sparse.csr\_matrix} того же размера,
под ответами для объектов выборки будем понимать \texttt{np.ndarray} размера $N$, где $N$ --- количество объектов в выборке, $D$ --- размер признакового пространства.

\textbf{Замечание 2.} Для всех функций можно задать аргументы по умолчанию, которые будут удобны в ваших эксперименте.
\\

Среди предоставленных файлов должны быть следующие модули и функции в них:

\begin{enumerate}
 \item Модуль \mdinlinecode{nearest\_neighbors}, содержащий собственную реализацию метода ближайших соседей.
  
  
 Класс \mdinlinecode{KNNClassifier}
 
 
 Описание методов:
\begin{enumerate}
 \item \mdinlinecode{\_\_init\_\_(self, k, strategy, metric, weights, test\_block\_size)} ---  конструктор класса.

 \begin{itemize}
  \item \mdinlinecode{k} --- число ближайших соседей в алгоритме ближайших соседей
  \item \mdinlinecode{strategy} --- алгоритм поиска ближайших соседей. Может принимать следующие значения:
  \begin{itemize}
  \item \texttt{\upquote{my\_own}} --- собственная реализация (например, на основе кода подсчёта евклидова расстояния между двумя множествами точек из задания №1)
  \item \texttt{\upquote{brute}} --- использование \mdinlinecode{sklearn.neighbors.NearestNeighbors(algorithm=\upquote{brute})}
  \item \texttt{\upquote{kd\_tree}} --- использование \mdinlinecode{sklearn.neighbors.NearestNeighbors(algorithm=\upquote{kd\_tree})}
  \item \texttt{\upquote{ball\_tree}} --- использование \mdinlinecode{sklearn.neighbors.NearestNeighbors(algorithm=\upquote{ball\_tree})}
  \end{itemize}
  
  \item \mdinlinecode{metric} --- название метрики, по которой считается расстояние между объектами. Может принимать следующие значения:
  \begin{itemize}
  \item \texttt{\upquote{euclidean}} --- евклидова метрика
  \item \texttt{\upquote{cosine}} --- косинусная метрика
  \end{itemize}
  \item \mdinlinecode{weights} --- переменная типа \mdinlinecode{bool}. Значение \mdinlinecode{True} означает, что нужно использовать взвешенный метод k ближайших соседей. 
  Во взвешенном методе ближайших соседей голос одного объекта равен $1 / (distance + \varepsilon)$, где $\varepsilon = 10^{-5}$.
  \item \mdinlinecode{test\_block\_size} --- размер блока данных для тестовой выборки
    
  %\item \textcolor{red}{\texttt{X\_train} --- обучающая выборка}
  %\item \textcolor{red}{\texttt{y\_train} --- ответы на объектах обучающей выборки}
 \end{itemize}
    \textbf{Замечание 1.}
 Для некоторых алгоритмов поиска ближайших соседей вам потребуется хранить обучающую выборку и ответы на ней.
 Некоторые алгоритмы не требуют хранения выборки, но требуют хранения дополнительной информации о её структуре.

  \textbf{Замечание 2.}
  При поиске k ближайших соседей некоторые методы строят в памяти матрицу попарных расстояний обучающей выборки и тестовой выборки.
  Рекомендуется написать функцию, которая ищет ближайших соседей блоками, то есть делает запросы ближайших соседей для первых N тестовых объектов,
  затем для следующих N, и так далее, и в конце объединяет полученные результаты.
 
  \textbf{Замечание 3.} 
  Стратегии \mdinlinecode{\upquote{kd\_tree}} и \mdinlinecode{\upquote{ball\_tree}} не могут принимать в качестве параметра метрики \mdinlinecode{\upquote{cosine}} или любой \mdinlinecode{Callable} объект. Для тестирования этих стратегий в качестве параметра
можно подавать строку: \mdinlinecode{\upquote{euclidean}}.
 
 \item \mdinlinecode{fit(self, X, y)}
 
  Описание параметров:
 \begin{itemize}
  \item \mdinlinecode{X} --- обучающая выборка объектов
  \item \mdinlinecode{y} --- ответы объектов на обучающей выборке
 \end{itemize}
 Метод производит обучение алгоритма с учётом стратегии указанной в параметре \mdinlinecode{strategy}.
\item \mdinlinecode{find\_kneighbors(self, X, return\_distance)}

  Описание параметров:
 \begin{itemize}
  \item \mdinlinecode{X} --- выборка объектов
  \item \mdinlinecode{return\_distance} --- переменная типа \mdinlinecode{bool}
 \end{itemize}
  Метод возвращает \mdinlinecode{tuple} из двух \texttt{np.ndarray} размера (\texttt{X.shape[0], k}). 
  \texttt{[i, j]} элемент первого массива должен быть равен расстоянию от \texttt{i}-го объекта, до его \texttt{j}-го ближайшего соседа.
  \texttt{[i, j]} элемент второго массива должен быть равен индексу \texttt{j}-ого ближайшего соседа из обучающей выборки для объекта с индексом \texttt{i}.
  
  Если \mdinlinecode{return\_distance=False}, возвращается только второй из указанных массивов.
  Метод должен использовать стратегию поиска указанную в параметре класса \mdinlinecode{strategy}.
\item \mdinlinecode{predict(self, X)}

  Описание параметров:
 \begin{itemize}
  \item \mdinlinecode{X} --- тестовая выборка объектов
 \end{itemize}
 Метод должен вернуть одномерный \texttt{np.ndarray} размера \texttt{X.shape[0]}, 
 состоящий из предсказаний алгоритма (меток классов) для объектов тестовой выборки.
 
\end{enumerate}

 \item Модуль \mdinlinecode{cross\_validation} с реализациями функций для применения кросс-валидации:
 \begin{enumerate}
 \item \mdinlinecode{kfold(n, n\_folds)}
 
 Описание параметров:
 \begin{itemize}
  \item \mdinlinecode{n} --- количество объектов в выборке
  \item \mdinlinecode{n\_folds} --- количество фолдов на которые делится выборка
 \end{itemize}
 Функция реализует генерацию индексов обучающей и валидационной выборки для кросс-валидации с \mdinlinecode{n\_folds} фолдами.
 Функция возвращает список длины \mdinlinecode{n\_folds}, каждый элемент списка --- кортеж из двух одномерных \texttt{np.ndarray}. 
 Первый массив содержит индексы обучающей подвыборки, а второй валидационной.
 
 \textbf{Замечение.} В случае когда число элементов выборки не кратно кол-ву фолдов, функция должна
делить выборку аналогично \mdinlinecode{sklearn.model\_selection.KFold}.
 
 %\item \textcolor{red}{ \texttt{stratified\_kfold(X, y, n\_folds)} (предполагаемый бонус)}
 
 %Описание параметров:
 %\begin{itemize}
 % \item \texttt{X} --- обучающая выборка, по которой делаются фолды
 % \item \texttt{y} --- ответы объектов на обучающей выборке
 % \item \texttt{n\_folds} --- количество фолдов на которые делится выборка
 %\end{itemize}
 %Функция реализует генерацию индексов обучающей и валидационной выборки для кросс-валидации с \texttt{n\_folds} фолдами со стратификацией классов.
 %Функция возвращает список длины \texttt{n\_folds}, каждый элемент списка кортеж из двух одномерных \texttt{np.ndarray}. 
 %Первый массив содержит индексы обучающей подвыборки, а второй валидационной.
 %Для каждого класса отношение количества объектов этого класса в обучающей выборке к количеству объектов этого класса в валидационной выборке должно быть одинаковым по всем разбиениям.

 
  \item \mdinlinecode{knn\_cross\_val\_score(X, y, k\_list, 
			score, cv, **kwargs)}
			
Описание параметров:
  \begin{itemize}
  \item \mdinlinecode{X} --- обучающая выборка
  \item \mdinlinecode{y} --- ответы объектов на обучающей выборке
  \item \mdinlinecode{k\_list} --- список из проверяемых значений для числа ближайших соседей, числа в списке упорядочены по возрастанию
  \item \mdinlinecode{score} --- название метрики, по которой оценивается качество алгоритма.
  Обязательно должна быть реализована метрика \upquote{accuracy} (доля правильно предсказанных ответов)
  \item \mdinlinecode{cv} --- список из кортежей, содержащих индексы обучающей и валидационной выборки --- выход функций \mdinlinecode{kfold} или \mdinlinecode{stratified\_kfold}.
  Если параметр не задан, необходимо внутри функции реализовать генерацию индексов с помощью функции \mdinlinecode{kfold}
  \item \mdinlinecode{**kwargs} --- параметры конструктора класса \mdinlinecode{KNNClassifier}


 \end{itemize}

 Функция для измерения метрики качества \mdinlinecode{score} алгоритма ближайших соседей, реализованного через класс \mdinlinecode{KNNclassifier}
 на кросс-валидации, заданной списком индексов \mdinlinecode{cv} для обучающей выборки \mdinlinecode{X}, ответов на ней \mdinlinecode{y}.
 Оценку качества метода ближайших соседей нужно рассчитать для нескольких значений $k$: $[k_1, \dots, k_n]$, $k_1 < k_2 < \dots < k_n$, заданных в \mdinlinecode{k\_list}.
 Сложность алгоритма для одного объекта из валидационной выборки должна иметь порядок $O(k_n)$.
 
Функция должна возвращать словарь, где ключами являются значения $k$, а элементами --- \texttt{np.ndarray} размера \mdinlinecode{len(cv)} с качеством на каждом фолде.
 
 \textbf{Замечание.}
 Для тестирования алгоритма удобно использовать функцию \mdinlinecode{cross\_val\_score} из библиотеки \mdinlinecode{scikit-learn}.
%  Нельзя использовать класс \verb|sklearn.neighbors.KNeighborsClassifier|, можно пользоваться готовыми реализациями поиска ближайших соседей. 
 \end{enumerate}
 
 \item Модуль \mdinlinecode{distances} с реализацией функции для вычисления расстояния:

\begin{enumerate}
 \item \mdinlinecode{euclidean\_distance(X, Y)}
 
 Описание параметров:
 \begin{itemize}
  \item \mdinlinecode{X} --- \texttt{np.ndarray} размера \texttt{$N \times D$}
  \item \mdinlinecode{Y} --- \texttt{np.ndarray} размера \texttt{$M \times D$}
 \end{itemize}
 Функция возвращает \texttt{np.ndarray} размера \texttt{$N \times M$}, каждый элемент которого --- евклидово расстояние между соответствующей парой векторов из массивов $X$ и $Y$. 

\textbf{Замечание.} 
Для тестирования алгоритма удобно использовать функцию \mdinlinecode{pdist} из библиотеки \mdinlinecode{scipy}.

\item \mdinlinecode{cosine\_distance(X, Y)}

 Описание параметров:
 \begin{itemize}
  \item \mdinlinecode{X} --- \texttt{np.ndarray} размера \texttt{$N \times D$}
  \item \mdinlinecode{Y} --- \texttt{np.ndarray} размера \texttt{$M \times D$}
 \end{itemize}
 Функция возвращает \texttt{np.ndarray} размера \texttt{$N \times M$}, каждый элемент которого --- косинусное расстояние между соответствующей парой векторов из массивов $X$ и $Y$. 

\textbf{Замечание.} 
Для тестирования алгоритма удобно использовать функцию \mdinlinecode{pdist} из библиотеки \mdinlinecode{scipy}.

\end{enumerate}
 

 
\end{enumerate}

%\section{Бонусные баллы}
%\begin{itemize}
%  \item
%    +0.25 балла. Качественное проведение дополнительного (не пересекающегося с основным заданием) мини-исследования по теме метрических алгоритмов: формулируется изучаемый вопрос, ставятся эксперименты, позволяющие на него ответить, делаются выводы.
%  \item
%    +0.5 балла. После сдачи задания будет составлен рейтинг решений задачи MNIST по точности на скрытом разбиении на обучение и контроль.
%    Авторы пяти лучших решений получат +0.5 балла.
%\end{itemize}

\section*{Бонусная часть}
\begin{enumerate}
%\item (до 4 баллов) Написать юнит-тесты к написанному коду. Юнит-тесты должны быть реализованы в отдельном модуле, в отчёте должно быть прописано, как именно юнит-тесты должны быть запущены.

\item (до 3 баллов) Написать параллельную реализацию поиска ближайших соседей (например, с помощью библиотек \mdinlinecode{joblib} или \mdinlinecode{numba})

\item (до 5 баллов) Улучшить качество работы метрических алгоритмов на датасете \texttt{MNIST} с помощью средств, не использующихся в задании. Например, можно реализовать ансамбль метрических алгоритмов, реализовать новые метрики, новые признаковые описания объектов. Размер бонуса зависит от величины улучшения и от изобретательности подхода.

\item (до 5 баллов) Качественное проведение дополнительного (не пересекающегося с основным заданием) исследования по теме метрических алгоритмов: формулируется изучаемый вопрос, ставятся эксперименты, позволяющие на него ответить, делаются выводы. Перед исследованием необходимо обсудить тему с преподавателем.
\end{enumerate}



\end{document}
